1.
              Connected computers that work together as a single system is called Cluster.In a computer system, a cluster is a group of 
  servers and other resources that act like a single system and enable high availability .
          Hadoop cluster is a special type of computational cluster designed for storing and analyzing vast amount of unstructured data
  in a distributed computing environment.It has 2 main components one is HDFS which stores data in distributed manner and other one is 
  mapreduce which does distributed data processing on the cluster.Hadoop clusters are often referred to as "shared nothing" systems ,
  because it will share only network ,the data is stored in different commodity machines and proccessing also done at different machines 
  and output is sent to master machine accordingly
  
  2.
   Hadoop components are rack-aware. For example, HDFS block placement will use rack awareness for fault tolerance by placing one block 
   replica on a different rack. This provides data availability in the event of a network switch failure or partition within the cluster.
   
